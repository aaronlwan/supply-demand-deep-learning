{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Imports and Data"
      ],
      "metadata": {
        "id": "GQmnLmpAKsYv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lWR26OljvNFJ"
      },
      "outputs": [],
      "source": [
        "!pip install mplfinance\n",
        "import mplfinance as mpl\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "spy_thirty_min = pd.DataFrame(np.array(pd.read_csv('/content/drive/MyDrive/SPY_qjrt28/SPY_30min.txt', header=None)), columns=['Time', 'Open', 'High', 'Low', 'Close', 'Volume'])\n",
        "spy_hourly = pd.DataFrame(np.array(pd.read_csv('/content/drive/MyDrive/SPY_qjrt28/SPY_1hour.txt', header=None)), columns=['Time', 'Open', 'High', 'Low', 'Close', 'Volume'])\n",
        "five_min_data = pd.DataFrame(np.array(pd.read_csv('/content/drive/MyDrive/SPY_qjrt28/SPY_5min.txt', header=None)), columns=['Time', 'Open', 'High', 'Low', 'Close', 'Volume'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYSDYpNW_EVP"
      },
      "source": [
        "Supply and Demand Helper Funcs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gN8NqCyzQ4I_"
      },
      "outputs": [],
      "source": [
        "# Helper Functions\n",
        "\n",
        "def get_change(candle):\n",
        "  diff = candle[4]/candle[1]\n",
        "  if candle[4] > candle[1]:\n",
        "    change = diff - 1\n",
        "  else:\n",
        "    change = 1 - diff\n",
        "\n",
        "  return change\n",
        "\n",
        "def no_long_wicks(candle, thresh_pct):\n",
        "  thresh = thresh_pct*get_change(candle)\n",
        "  candle_open, candle_high, candle_low, candle_close = candle[1], candle[2], candle[3], candle[4]\n",
        "  if candle_close > candle_open:\n",
        "    if candle_high/candle_close - 1 < thresh and candle_open/candle_low - 1 < thresh:\n",
        "      return True\n",
        "  else:\n",
        "    if candle_high/candle_open - 1 < thresh and candle_close/candle_low - 1 < thresh:\n",
        "      return True\n",
        "  return False\n",
        "\n",
        "\n",
        "def is_basing(candle, next_candle_change, thresh_pct):\n",
        "  \"\"\" Criterion for basing candle\n",
        "  1. Must be less than half of the next candle\n",
        "  \"\"\"\n",
        "  if get_change(candle) > 0.5*next_candle_change:\n",
        "    return False\n",
        "  \n",
        "  \"\"\" \n",
        "  2. Must have small wicks, meaning if it is a green candle, high is close to \n",
        "  close and low is close to open, and if it is red, then vice versa.\n",
        "\n",
        "  \"Closeness\" is dependent on the candle's change. Define closeness threshold as within thresh_pct of the candle's change \n",
        "  \"\"\"\n",
        "  return no_long_wicks(candle, thresh_pct)\n",
        "\n",
        "def is_zone(candle, next_candle, large_change, thresh_pct, supply, demand):\n",
        "\n",
        "  # Criterion for Supply/Demand Zone:\n",
        "  # 1. Next candle must have large % change between open and close\n",
        "  if get_change(next_candle) >= large_change:\n",
        "    # 2. Next candle must not have long wicks\n",
        "    if no_long_wicks(next_candle, thresh_pct):\n",
        "      # 3. Must have basing candle\n",
        "      if is_basing(candle, get_change(next_candle), thresh_pct):\n",
        "        if next_candle[4] > next_candle[1] and demand:\n",
        "          return True\n",
        "        elif next_candle[4] < next_candle[1] and supply:\n",
        "          return True\n",
        "  return False\n",
        "\n",
        "def get_zones(data, large_change, thresh_pct, supply, demand):\n",
        "  zones = []\n",
        "  for i in range(len(data.values)):\n",
        "    if i + 1 < len(data.values):\n",
        "      candle = data.values[i]\n",
        "      next_candle = data.values[i + 1]\n",
        "      if is_zone(candle, next_candle, large_change, thresh_pct, supply, demand):\n",
        "          zones.append([candle, next_candle])\n",
        "  return np.array(zones)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHcznQYIv-jD"
      },
      "source": [
        "Get Zones for Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4R_NCJ7v1Jm",
        "outputId": "8a499f4a-2d24-4ab4-db7f-9d3f9bca945c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(812, 2, 6)\n"
          ]
        }
      ],
      "source": [
        "zones = get_zones(spy_hourly, 0.0018, 0.8, False, True)\n",
        "print(zones.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function for Compiling Model Data from Zone Data"
      ],
      "metadata": {
        "id": "MD0Bg02JK9VY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Input: Image of TPO profile representing 100 five-minute intervals of price data before price retests supply/demand zone"
      ],
      "metadata": {
        "id": "xqKOVOVdLbCm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Output: 0 (After 50 mins of retesting supply/demand zone, price does not increase) or 1 (Price does increase after 50 mins)"
      ],
      "metadata": {
        "id": "MNDuuT5JLr1M"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OUhHbIp4wQsI"
      },
      "outputs": [],
      "source": [
        "def get_model_data_cnn(five_min_data, thirty_min_data, zones):\n",
        "  outcome_context = []\n",
        "  outcome = []\n",
        "\n",
        "  five_min_times = five_min_data.values[:, 0]\n",
        "  thirty_min_times = thirty_min_data.values[:, 0]\n",
        "\n",
        "  for zone in zones:\n",
        "    try:\n",
        "      # Zone start time\n",
        "      zone_start = zone[0][0]\n",
        "      \n",
        "      # Find index of zone start time in five min data\n",
        "      five_min_idx = np.where(five_min_times==zone_start)[0]\n",
        "      thirty_min_idx = np.where(thirty_min_times==zone_start)[0]\n",
        "\n",
        "      if len(five_min_idx) == 1 and len(thirty_min_idx) == 1:\n",
        "\n",
        "        # Collect 100 candles of outcome context\n",
        "        # Scan forward until retest of zone\n",
        "        search = five_min_idx + 24 \n",
        "\n",
        "        # Supply or Demand\n",
        "        if zone[1][4] > zone[1][1]:\n",
        "          # Zone price level\n",
        "          if zone[0][4] > zone[0][1]:\n",
        "            price_level = zone[0][4]\n",
        "          else:\n",
        "            price_level = zone[0][1]\n",
        "          while np.all(price_level <= five_min_data.values[search][:, [1, 2, 3, 4]]):\n",
        "            search += 1\n",
        "\n",
        "        else:\n",
        "          if zone[0][4] > zone[0][1]:\n",
        "            price_level = zone[0][1]\n",
        "          else:\n",
        "            price_level = zone[0][4]\n",
        "          while np.all(price_level >= five_min_data.values[search][:, [1, 2, 3, 4]]):\n",
        "            search += 1\n",
        "\n",
        "        search += 1\n",
        "        start = search[0] - 100\n",
        "        end = search[0]\n",
        "        outcome_context.append(five_min_data.values[start:end])\n",
        "\n",
        "        start = search[0]\n",
        "        end = search[0] + 10\n",
        "        if zone[1][4] > zone[1][1]:\n",
        "          if five_min_data.values[end][4] > five_min_data.values[search[0]][4]:\n",
        "            result = 1\n",
        "          else:\n",
        "            result = 0\n",
        "        else:\n",
        "          if zone[0][4] > zone[0][1]:\n",
        "            price_level = zone[0][1]\n",
        "          else:\n",
        "            price_level = zone[0][4]\n",
        "          if five_min_data.values[end][4] < five_min_data.values[search[0]][4]:\n",
        "            result = 1\n",
        "          else:\n",
        "            result = 0\n",
        "        outcome.append(result)\n",
        "      \n",
        "    except:\n",
        "      pass\n",
        "\n",
        "  outcome_context = np.array(outcome_context)\n",
        "  outcome = np.array(outcome)\n",
        "\n",
        "  return outcome_context, outcome\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oXcwQHftwYR8"
      },
      "outputs": [],
      "source": [
        "outcome_context, outcome = get_model_data_cnn(five_min_data, spy_thirty_min, zones)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HfP8avz5rBy4",
        "outputId": "38233134-6851-4d5e-9a2d-3298f68088ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(714, 100, 6) (714,)\n"
          ]
        }
      ],
      "source": [
        "print(outcome_context.shape, outcome.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Helper Functions for Creating Images of Time-Price-Opportunity Profiles"
      ],
      "metadata": {
        "id": "jTx7MoWfLJcD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x0ejOMafNOKA"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import patches\n",
        "from PIL import Image\n",
        "from keras.preprocessing.image import img_to_array\n",
        "import cv2\n",
        "\n",
        "def find_nearest(array, value):\n",
        "    array = np.asarray(array)\n",
        "    idx = (np.abs(array - value)).argmin()\n",
        "    return array[idx]\n",
        "\n",
        "def float2color(percentage):\n",
        "    color_part_dec = int(255 * percentage)\n",
        "    color_part_hex = str(hex(color_part_dec))[2:]\n",
        "    return \"#\" + color_part_hex + color_part_hex + color_part_hex\n",
        "\n",
        "\n",
        "def find_longest_row(tpo):\n",
        "  longest = 0\n",
        "  for level in tpo:\n",
        "    if len(tpo[level]) > longest:\n",
        "      longest = len(tpo[level])\n",
        "  return longest\n",
        "\n",
        "\n",
        "def make_multi_tpo(series, num_tpo):\n",
        "  # Dict of price levels for each group\n",
        "  tpos = {}\n",
        "  for i in range(num_tpo):\n",
        "    minprice = np.round(min(series[:, 3]), 2)\n",
        "    maxprice = np.round(max(series[:, 4]), 2)\n",
        "    levels = {}\n",
        "    p = minprice\n",
        "    increment = np.round((maxprice - minprice)/20, 2)\n",
        "    while p <= maxprice:\n",
        "      levels[p] = []\n",
        "      p += increment\n",
        "    tpos[i] = levels\n",
        "\n",
        "  # Make TPO dict\n",
        "  start = 0\n",
        "  end = int(len(series)/num_tpo)\n",
        "  i = 230\n",
        "  for j in range(num_tpo):\n",
        "    levels = tpos[j]\n",
        "    prices = np.array(list(levels.keys()))\n",
        "    for row in series[start:end]:\n",
        "      price = np.round(row[4], 2)\n",
        "      closest = find_nearest(prices, price)\n",
        "      if levels[closest]:\n",
        "        levels[closest].append(i)\n",
        "      else:\n",
        "        levels[closest] = [i]\n",
        "    i -= 50\n",
        "    start += int(len(series)/num_tpo)\n",
        "    end += int(len(series)/num_tpo)\n",
        "\n",
        "  # Blank image\n",
        "  fig = plt.figure(figsize=(20,5))\n",
        "  plt.savefig('greyscale.png')\n",
        "  plt.close()\n",
        "\n",
        "  # Load image\n",
        "  im = Image.open('greyscale.png')\n",
        "  fig, ax = plt.subplots()\n",
        "  plt.axis('off')\n",
        "  ax.imshow(im)\n",
        "  shift = 0\n",
        "\n",
        "  # Draw Squares\n",
        "  for i in tpos:\n",
        "    levels = tpos[i]\n",
        "    ycoord = 0\n",
        "    for level in levels:\n",
        "      xcoord = shift\n",
        "      for val in levels[level]:\n",
        "        color = float2color(val/255)\n",
        "        rect = patches.Rectangle((xcoord, ycoord), 25, 25, linewidth=0, edgecolor=color, facecolor=color)\n",
        "        ax.add_patch(rect)\n",
        "        xcoord += 25\n",
        "      ycoord+=25\n",
        "    shift += 25*find_longest_row(levels)\n",
        "\n",
        "  plt.savefig('greyscale')\n",
        "  plt.close()\n",
        "  img = Image.open('greyscale.png')\n",
        "\n",
        "  # Crop\n",
        "  left = 80\n",
        "  top = 181\n",
        "  right = 500\n",
        "  bottom = 304\n",
        "  img = img.crop((left, top, right, bottom))  \n",
        "  img_array = img_to_array(img)\n",
        "  plt.close()\n",
        "\n",
        "  return img_array"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert Time-Series Data to TPO Profiles"
      ],
      "metadata": {
        "id": "pL6nHozLLVxM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "82aRwNs4POj-"
      },
      "outputs": [],
      "source": [
        "inputs = []\n",
        "for i in range(len(outcome_context)):\n",
        "  inputs.append(make_multi_tpo(outcome_context[i], 4))\n",
        "  np.save('drive/MyDrive/Project/img_arrays', np.array(inputs))\n",
        "  np.save('drive/MyDrive/Project/outcomes', np.array(outcome[:i+1]))\n",
        "  print(len(inputs))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = np.load('drive/MyDrive/Project/img_arrays.npy')\n",
        "outcome = np.load('drive/MyDrive/Project/outcomes.npy')"
      ],
      "metadata": {
        "id": "GKC53jHvWfZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPaI9GMIZTiO",
        "outputId": "5fdfc6b5-a4ea-4694-ae9a-2474ce3b3f77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(714, 123, 420, 4) (714,)\n"
          ]
        }
      ],
      "source": [
        "print(inputs.shape, outcome.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sample of TPO Profile"
      ],
      "metadata": {
        "id": "gx4tUW_HMOYJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "JIKSk-NIbu_h",
        "outputId": "a34e9461-43ce-4e16-8b16-a29fb39b8545"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGBA size=420x123 at 0x7F0278D73F50>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaQAAAB7CAYAAAA7U/R7AAACyUlEQVR4nO3d0aniUBRAUTPYisXYjMWkGXvRYvL+BzODmpfs6FqfKiEfwubA4d5hmqbpAAAb+7P1CwDA4SBIAEQIEgAJggRAgiABkHDc+gWeNY7jw88vl8vKbwLAkkxIACQIEgAJggRAgiABkCBIACTsbstuztz23Rps+AG8z4QEQIIgAZAgSAAkCBIACYIEQMLxfr8//OJ0Oq38KuuyGQfQYkICIEGQAEgQJAASBAmABEECIOH4Kdt0tuYA9s2EBECCIAGQIEgAJAgSAAmCBECCIAGQMHu46iu2XCGfu8LcOjjAPpiQAEgQJAASBAmABEECIEGQAEgQJAASBAmABEECIEGQAEgQJAASBAmAhOOSD1vyXDwAvosJCYAEQQIgQZAASBAkABIECYCEl7bstrwZ9nq9PvzczbAA+2ZCAiBBkABIECQAEgQJgARBAiBhuN1u09Yv8bctt/gA2IYJCYAEQQIgQZAASBAkABIECYAEQQIgYdErzNdY1x7HcZHnOIwVoMWEBECCIAGQIEgAJAgSAAmCBEDC0UGm7zufz0/9fu4a9qphGBZ5zjTlzvEFQkxIACQIEgAJggRAgiABkCBIACQsepbdlopn0+1tm+63vbKtZzMPvocJCYAEQQIgQZAASBAkABIECYCEYbLG9LZvPcvOXwdYkgkJgARBAiBBkABIECQAEgQJgISPOctuT57dyquyfQcsyYQEQIIgAZAgSAAkCBIACYIEQIIgAZBg7ftDLXmA67NXjz/7e2viwOFgQgIgQpAASBAkABIECYAEQQIgwZbdzu3pOnTbdMC/mJAASBAkABIECYAEQQIgQZAASBgmq0/8h6vKgTWYkABIECQAEgQJgARBAiBBkABIECQAEgQJgARBAiBBkABIECQAEgQJgAQ3xvKyuTPuluS8PPgeJiQAEgQJgARBAiBBkABIECQAEn4A/3FT46yTvwYAAAAASUVORK5CYII=\n"
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "from keras.preprocessing.image import array_to_img\n",
        "array_to_img(inputs[np.random.randint(len(inputs))])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN:"
      ],
      "metadata": {
        "id": "t8jN01aYLqaT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--6O8V_TYPL_",
        "outputId": "50dc19c0-ce7a-4b6a-f068-dd7de4a7f125"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"CNN\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 123, 420, 4)]     0         \n",
            "                                                                 \n",
            " conv2d_15 (Conv2D)          (None, 121, 418, 3)       111       \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 121, 418, 3)       0         \n",
            "                                                                 \n",
            " max_pooling2d_12 (MaxPoolin  (None, 60, 209, 3)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_16 (Conv2D)          (None, 58, 207, 3)        84        \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 58, 207, 3)        0         \n",
            "                                                                 \n",
            " max_pooling2d_13 (MaxPoolin  (None, 29, 103, 3)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_17 (Conv2D)          (None, 27, 101, 3)        84        \n",
            "                                                                 \n",
            " dropout_14 (Dropout)        (None, 27, 101, 3)        0         \n",
            "                                                                 \n",
            " max_pooling2d_14 (MaxPoolin  (None, 13, 50, 3)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_18 (Conv2D)          (None, 11, 48, 3)         84        \n",
            "                                                                 \n",
            " dropout_15 (Dropout)        (None, 11, 48, 3)         0         \n",
            "                                                                 \n",
            " max_pooling2d_15 (MaxPoolin  (None, 5, 24, 3)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_19 (Conv2D)          (None, 3, 22, 1)          28        \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 66)                0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 32)                2144      \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,080\n",
            "Trainable params: 3,080\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from keras.layers import Conv2D, Dense, Input, MaxPool2D, Flatten, Dropout, Reshape\n",
        "from keras.constraints import min_max_norm, unit_norm\n",
        "from keras import Model\n",
        "\n",
        "\n",
        "def cnn():\n",
        "  x_input = Input(shape=(123, 420, 4)) \n",
        "  x = Conv2D(filters=3, kernel_size=(3,3), padding='valid', activation='relu', kernel_initializer='he_normal')(x_input)\n",
        "  x = Dropout(0.2)(x)\n",
        "  x = MaxPool2D()(x)\n",
        "  x = Conv2D(filters=3, kernel_size=(3,3), padding='valid', activation='relu', kernel_initializer='he_normal')(x)\n",
        "  x = Dropout(0.2)(x)\n",
        "  x = MaxPool2D()(x)\n",
        "  x = Conv2D(filters=3, kernel_size=(3,3), padding='valid', activation='relu', kernel_initializer='he_normal')(x)\n",
        "  x = Dropout(0.2)(x)\n",
        "  x = MaxPool2D()(x)\n",
        "  x = Conv2D(filters=3, kernel_size=(3,3), padding='valid', activation='relu', kernel_initializer='he_normal')(x)\n",
        "  x = Dropout(0.2)(x)\n",
        "  x = MaxPool2D()(x)\n",
        "  x = Conv2D(filters=1, kernel_size=(3,3), padding='valid', activation='relu', kernel_initializer='he_normal')(x)\n",
        "  x = Flatten()(x)\n",
        "\n",
        "  x = Dense(32, activation='relu')(x)\n",
        "  x = Dense(16, activation='relu')(x)\n",
        "  out = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "  model = Model(inputs= x_input, outputs = out, name='CNN')\n",
        "  return model\n",
        "\n",
        "cnn = cnn()\n",
        "cnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "cnn.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SVl240dwawM0"
      },
      "outputs": [],
      "source": [
        "inputs = np.array(inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6dr0_jhIayXp"
      },
      "outputs": [],
      "source": [
        "split = int(len(inputs)*0.7)\n",
        "input_train, input_test, output_train, output_test = inputs[:split], inputs[split:], outcome[:split], outcome[split:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1Fm69n2FTjk",
        "outputId": "dd4620e0-584a-4b63-8cb3-45811a768ecb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(array([0, 1]), array([107, 108]))\n"
          ]
        }
      ],
      "source": [
        "print(np.unique(output_test, return_counts=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ts4pDto3aei3",
        "outputId": "d0b89ff0-9484-4478-ad56-3c19b5133a37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "16/16 [==============================] - 8s 517ms/step - loss: 0.6842 - accuracy: 0.5271 - val_loss: 0.6885 - val_accuracy: 0.5674\n",
            "Epoch 2/20\n",
            "16/16 [==============================] - 11s 695ms/step - loss: 0.6816 - accuracy: 0.5691 - val_loss: 0.6869 - val_accuracy: 0.5767\n",
            "Epoch 3/20\n",
            "16/16 [==============================] - 13s 784ms/step - loss: 0.6874 - accuracy: 0.5511 - val_loss: 0.6871 - val_accuracy: 0.5628\n",
            "Epoch 4/20\n",
            "16/16 [==============================] - 8s 515ms/step - loss: 0.6830 - accuracy: 0.5431 - val_loss: 0.6867 - val_accuracy: 0.5674\n",
            "Epoch 5/20\n",
            "16/16 [==============================] - 8s 515ms/step - loss: 0.6866 - accuracy: 0.5411 - val_loss: 0.6855 - val_accuracy: 0.5814\n",
            "Epoch 6/20\n",
            "16/16 [==============================] - 8s 516ms/step - loss: 0.6777 - accuracy: 0.5251 - val_loss: 0.6873 - val_accuracy: 0.5814\n",
            "Epoch 7/20\n",
            "16/16 [==============================] - 8s 514ms/step - loss: 0.6698 - accuracy: 0.5531 - val_loss: 0.6913 - val_accuracy: 0.5535\n",
            "Epoch 8/20\n",
            "16/16 [==============================] - 8s 514ms/step - loss: 0.6715 - accuracy: 0.5832 - val_loss: 0.6900 - val_accuracy: 0.5349\n",
            "Epoch 9/20\n",
            "16/16 [==============================] - 8s 516ms/step - loss: 0.6928 - accuracy: 0.5371 - val_loss: 0.6873 - val_accuracy: 0.5581\n",
            "Epoch 10/20\n",
            "16/16 [==============================] - 8s 516ms/step - loss: 0.6830 - accuracy: 0.5411 - val_loss: 0.6859 - val_accuracy: 0.5953\n",
            "Epoch 11/20\n",
            "16/16 [==============================] - 9s 597ms/step - loss: 0.6833 - accuracy: 0.5471 - val_loss: 0.6863 - val_accuracy: 0.5814\n",
            "Epoch 12/20\n",
            "16/16 [==============================] - 8s 515ms/step - loss: 0.6641 - accuracy: 0.5631 - val_loss: 0.6872 - val_accuracy: 0.5581\n",
            "Epoch 13/20\n",
            "16/16 [==============================] - 8s 515ms/step - loss: 0.6820 - accuracy: 0.5711 - val_loss: 0.6871 - val_accuracy: 0.5721\n",
            "Epoch 14/20\n",
            "16/16 [==============================] - 8s 515ms/step - loss: 0.6827 - accuracy: 0.5671 - val_loss: 0.6863 - val_accuracy: 0.5907\n",
            "Epoch 15/20\n",
            "16/16 [==============================] - 9s 544ms/step - loss: 0.6799 - accuracy: 0.5611 - val_loss: 0.6874 - val_accuracy: 0.5860\n",
            "Epoch 16/20\n",
            "16/16 [==============================] - 8s 516ms/step - loss: 0.6693 - accuracy: 0.5671 - val_loss: 0.6883 - val_accuracy: 0.5488\n",
            "Epoch 17/20\n",
            "16/16 [==============================] - 8s 514ms/step - loss: 0.6755 - accuracy: 0.5752 - val_loss: 0.6878 - val_accuracy: 0.5395\n",
            "Epoch 18/20\n",
            "16/16 [==============================] - 9s 561ms/step - loss: 0.6723 - accuracy: 0.5711 - val_loss: 0.6895 - val_accuracy: 0.5302\n",
            "Epoch 19/20\n",
            "16/16 [==============================] - 8s 514ms/step - loss: 0.6738 - accuracy: 0.5611 - val_loss: 0.6905 - val_accuracy: 0.5535\n",
            "Epoch 20/20\n",
            "16/16 [==============================] - 8s 516ms/step - loss: 0.6647 - accuracy: 0.5892 - val_loss: 0.6887 - val_accuracy: 0.5628\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0270154f10>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "cnn.fit(input_train, output_train, validation_data=(input_test, output_test), batch_size=32, epochs=20)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate Model"
      ],
      "metadata": {
        "id": "MQYzWy7SasBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We need the closing value of the outcome and the stop loss value (bottom of zone)\n",
        "\n",
        "def get_backtesting_data(five_min_data, thirty_min_data, zones):\n",
        "  outcome_price = []\n",
        "  stop_losses = []\n",
        "  supply_or_demand = []\n",
        "  entry = []\n",
        "\n",
        "  five_min_times = five_min_data.values[:, 0]\n",
        "  thirty_min_times = thirty_min_data.values[:, 0]\n",
        "  i = 0\n",
        "  for zone in zones:\n",
        "    i += 1\n",
        "    try:\n",
        "      # Zone start time\n",
        "      zone_start = zone[0][0]\n",
        "      \n",
        "      # Find index of zone start time in five min data\n",
        "      five_min_idx = np.where(five_min_times==zone_start)[0]\n",
        "      thirty_min_idx = np.where(thirty_min_times==zone_start)[0]\n",
        "\n",
        "      if len(five_min_idx) == 1 and len(thirty_min_idx) == 1:\n",
        "      \n",
        "        # Scan forward until retest of zone\n",
        "        search = five_min_idx + 24 \n",
        "\n",
        "        # Supply or Demand\n",
        "        if zone[1][4] > zone[1][1]:\n",
        "          # Zone price level\n",
        "          if zone[0][4] > zone[0][1]:\n",
        "            price_level = zone[0][4]\n",
        "          else:\n",
        "            price_level = zone[0][1]\n",
        "\n",
        "          while np.all(price_level <= five_min_data.values[search][:, [1, 2, 3, 4]]):\n",
        "            search += 1\n",
        "\n",
        "        else:\n",
        "          if zone[0][4] > zone[0][1]:\n",
        "            price_level = zone[0][1]\n",
        "          else:\n",
        "            price_level = zone[0][4]\n",
        "          \n",
        "\n",
        "          while np.all(price_level >= five_min_data.values[search][:, [1, 2, 3, 4]]):\n",
        "            search += 1\n",
        "\n",
        "        entry.append(five_min_data.values[search[0]][4])\n",
        "        end = search[0] + 10\n",
        "        outcome_price.append(five_min_data.values[end][4])\n",
        "\n",
        "        if zone[1][4] > zone[1][1]:\n",
        "            supply_or_demand.append('demand')\n",
        "          \n",
        "            if zone[0][3] < zone[1][3]:\n",
        "              stop_losses.append(zone[0][3])\n",
        "            else:\n",
        "              stop_losses.append(zone[1][3])\n",
        "\n",
        "        else:\n",
        "          supply_or_demand.append('supply')\n",
        "          \n",
        "          if zone[0][2] > zone[1][2]:\n",
        "            stop_losses.append(zone[0][2])\n",
        "          else:\n",
        "            stop_losses.append(zone[1][2])\n",
        "\n",
        "    except:\n",
        "      pass\n",
        "\n",
        "  outcome_price = np.array(outcome_price)\n",
        "  stop_losses = np.array(stop_losses)\n",
        "  supply_or_demand = np.array(supply_or_demand)\n",
        "  entry = np.array(entry)\n",
        "\n",
        "  return outcome_price, stop_losses, supply_or_demand, entry"
      ],
      "metadata": {
        "id": "sI5A6TGaavw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outcome_price, stop_loss, supply_or_demand, entry = get_backtesting_data(five_min_data, spy_thirty_min, zones)"
      ],
      "metadata": {
        "id": "RD1-ymqYiR9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outcome_price_test, stop_loss_test, supply_or_demand_test, entry_test = outcome_price[split:], stop_loss[split:], supply_or_demand[split:], entry[split:]"
      ],
      "metadata": {
        "id": "BA9vCB1TiUz4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = cnn.predict(input_test)\n",
        "\n",
        "wins = []\n",
        "losses = []\n",
        "with_model_capital = 1000\n",
        "\n",
        "for i in range(len(preds)):\n",
        "  if preds[i] > .5:\n",
        "    if supply_or_demand_test[i] == 'demand':\n",
        "      if outcome_price_test[i] > entry_test[i]:\n",
        "        wins.append(outcome_price_test[i]/entry_test[i] - 1)\n",
        "        with_model_capital *= outcome_price_test[i]/entry_test[i]\n",
        "      elif stop_loss_test[i] > outcome_price_test[i] and stop_loss_test[i] < entry_test[i]:\n",
        "        losses.append(1 - stop_loss_test[i]/entry_test[i])\n",
        "        with_model_capital *= stop_loss_test[i]/entry_test[i]\n",
        "      else:\n",
        "        losses.append(1 - outcome_price_test[i]/entry_test[i])\n",
        "        with_model_capital *= outcome_price_test[i]/entry_test[i]\n",
        "    else:\n",
        "      if outcome_price_test[i] < entry_test[i]:\n",
        "        wins.append(1 - outcome_price_test[i]/entry_test[i])\n",
        "        with_model_capital *= entry_test[i]/outcome_price_test[i]\n",
        "\n",
        "      elif stop_loss_test[i] < outcome_price_test[i] and stop_loss_test[i] > entry_test[i]:\n",
        "        losses.append(stop_loss_test[i]/entry_test[i] - 1)\n",
        "        with_model_capital *= entry_test[i]/stop_loss_test[i]\n",
        "\n",
        "      else:\n",
        "        losses.append(outcome_price_test[i]/entry_test[i] - 1)\n",
        "        with_model_capital *= entry_test[i]/outcome_price_test[i]\n",
        "\n",
        "print('Trading w/ Model')\n",
        "print('Profit-Loss-Ratio', np.mean(wins)/np.mean(losses))\n",
        "print('Win rate', len(wins)/(len(wins) + len(losses)))\n",
        "print('Total Trades:', len(wins) + len(losses))\n",
        "return_w_model = (with_model_capital/1000 - 1)*100\n",
        "print('Pct Return:', return_w_model, '%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vO8mnzViZDu",
        "outputId": "a0143b33-e1ec-4ab6-b375-9314dee9c039"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trading w/ Model\n",
            "Profit-Loss-Ratio 1.763728134167542\n",
            "Win rate 0.5232558139534884\n",
            "Total Trades: 172\n",
            "Pct Return: 11.369377885478137 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "no_model_wins = []\n",
        "no_model_losses = []\n",
        "no_model_capital = 1000\n",
        "\n",
        "for i in range(len(supply_or_demand_test)):\n",
        "  if supply_or_demand_test[i] == 'demand':\n",
        "    if outcome_price_test[i] > entry_test[i]:\n",
        "      no_model_wins.append(outcome_price_test[i]/entry_test[i] - 1)\n",
        "      no_model_capital *= outcome_price_test[i]/entry_test[i]\n",
        "\n",
        "    elif stop_loss_test[i] > outcome_price_test[i] and stop_loss_test[i] < entry_test[i]:\n",
        "      no_model_losses.append(1 - stop_loss_test[i]/entry_test[i])\n",
        "      no_model_capital *= stop_loss_test[i]/entry_test[i]\n",
        "\n",
        "    else:\n",
        "      no_model_losses.append(1 - outcome_price_test[i]/entry_test[i])\n",
        "      no_model_capital *= outcome_price_test[i]/entry_test[i]\n",
        "\n",
        "  else:\n",
        "    if outcome_price_test[i] < entry_test[i]:\n",
        "      no_model_wins.append(1 - outcome_price_test[i]/entry_test[i])\n",
        "      no_model_capital *= entry_test[i]/outcome_price_test[i]\n",
        "\n",
        "    elif stop_loss_test[i] < outcome_price_test[i] and stop_loss_test[i] > entry_test[i]:\n",
        "      no_model_losses.append(stop_loss_test[i]/entry_test[i] - 1)\n",
        "      no_model_capital *= entry_test[i]/stop_loss_test[i]\n",
        "\n",
        "    else:\n",
        "      no_model_losses.append(outcome_price_test[i]/entry_test[i] - 1)\n",
        "      no_model_capital *= entry_test[i]/outcome_price_test[i]\n",
        "\n",
        "\n",
        "print('Trading w/o Model')\n",
        "print('Profit-Loss-Ratio', np.mean(no_model_wins)/np.mean(no_model_losses))\n",
        "print('Win rate', len(no_model_wins)/(len(no_model_wins) + len(no_model_losses)))\n",
        "print('Total Trades:', len(no_model_wins) + len(no_model_losses))\n",
        "return_no_model = 100*(no_model_capital/1000 - 1)\n",
        "print('Pct Return:', return_no_model, '%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWQvLHpviZ5K",
        "outputId": "4ec3b1a0-ee45-496a-fc6d-3eb90452e997"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trading w/o Model\n",
            "Profit-Loss-Ratio 1.568046306086784\n",
            "Win rate 0.49767441860465117\n",
            "Total Trades: 215\n",
            "Pct Return: 9.669090324665142 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('% Increase in return by using model:', (return_w_model/return_no_model - 1)*100, '%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLyM1Vm6g75q",
        "outputId": "82550f91-a61e-4bd2-e603-557eaaba3500"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "% Increase in return by using model: 17.5847727523621 %\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}